import pandas as pd
import torch
from transformers import BartForSequenceClassification, BartTokenizer, AdamW
from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, AdamW
from sklearn.model_selection import train_test_split


df = pd.read_csv("Cancer_Data.csv")
df


x = df.drop("diagnosis", axis=1)  # Features
y = df["diagnosis"]  # Target


# Divida os dados em conjuntos de treinamento, validação e teste
train_texts, val_texts, train_labels, val_labels = train_test_split(x, y, test_size=0.2, random_state=42)


# Carregue o tokenizer e o modelo BART para classificação
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')


num_classes = len(set(labels)) 


# Modelo LLM
model = BartForSequenceClassification.from_pretrained('facebook/bart-large', num_labels=num_classes)



